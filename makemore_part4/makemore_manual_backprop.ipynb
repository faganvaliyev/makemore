{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t0rMzh3RDfJy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttusUP9wDfJ0",
        "outputId": "9f535cbf-9e32-4b58-ee4d-ea7bbef42297"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['zyell', 'zyheem', 'zykeem', 'zylas', 'zyran', 'zyrie', 'zyron', 'zzyzx']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read all the words\n",
        "file_path = r'C:\\Users\\User\\OneDrive\\Desktop\\all_in_one\\build_makemore\\names.txt'\n",
        "words = open(file_path).read().splitlines()\n",
        "words[-8:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTTudbBADfJ3",
        "outputId": "6fa837ab-4a28-410e-aad2-e772fb1c1e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mapping ro/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehz74DeADfJ4",
        "outputId": "fc390759-d679-41ef-c397-8098b66dfbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build dataset\n",
        "block_size = 3\n",
        "\n",
        "def build_dataset(words):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for w in words:\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "            ix = stoi[ch]\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "            context = context[1:] + [ix] # crop and append\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "    print(X.shape, Y.shape)\n",
        "    return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xtest, Ytest = build_dataset(words[n2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UGHMCCjJDfJ6"
      },
      "outputs": [],
      "source": [
        "# utlity function to compare manuel gradient to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "    ex = torch.all(dt == t.grad).item()\n",
        "    app = torch.allclose(dt, t.grad)\n",
        "    maxdiff = (dt - t.grad).abs().max().item()\n",
        "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUdlYYm1DfJ6",
        "outputId": "8b15dba0-ba7d-4872-96d1-726a41f2ac15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4137\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10 # the dimensionality of the character  embedding vector\n",
        "n_hidden = 64 # the number of neurons in one hidden layer of MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(126372837)\n",
        "C = torch.randn((vocab_size, n_embd), generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3) / ((vocab_size * n_embd)**0.5)\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn(n_hidden, vocab_size, generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
        "# BatchNorm paramaters\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways because sometimes\n",
        "# initializating with e.g. all zeros could mask an incorrect implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Em6FRiffDfJ7"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "n = batch_size # shorter variable also, for convenince\n",
        "# minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0],(batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0eeyfRXDfJ8",
        "outputId": "24dba4ac-29a8-465f-fccf-e8d5feb7cde6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.3917, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#forwars pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "emb = C[Xb]\n",
        "embcat = emb.view(emb.shape[0], -1)\n",
        "#Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# BatchNorm Layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdims=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1) * bndiff2.sum(0, keepdims=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact)\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logits_max = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logits_max\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdim=True)\n",
        "counts_sum_inv = counts_sum **-1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = - logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logits_max, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1QhrR2DfJ9",
        "outputId": "d5bd14c9-197f-4e60-ef81-d980b7ab29d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "bndiff          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnmeani         | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "embcat          | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "b1              | exact: False | approximate: False | maxdiff: 1.1641532182693481e-08\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ],
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "dprobs = (1.0 / probs) * dlogprobs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dnorm_logits = counts * dcounts\n",
        "dlogits = dnorm_logits.clone()\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "dbndiff = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "dbndiff += (2*bndiff) * dbndiff2\n",
        "dhprebn = dbndiff.clone()\n",
        "dbnmeani = (-dbndiff).sum(0)\n",
        "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)\n",
        "demb = dembcat.view(emb.shape)\n",
        "dC = torch.zeros_like(C)\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k,j]\n",
        "    dC[ix] += demb[k,j]\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logits_max)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RL_xwpWDfJ-",
        "outputId": "50bf3ecc-12ba-42e3-e7bf-5a18b506dd83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.391657829284668 diff: 2.384185791015625e-07\n"
          ]
        }
      ],
      "source": [
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "\n",
        "# now\n",
        "lost_fast = F.cross_entropy(logits,Yb)\n",
        "print(lost_fast.item(), 'diff:', (lost_fast-loss).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYEvuQdxDfJ_",
        "outputId": "1e4d6382-186e-4eae-d489-352818b3e14b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits          | exact: False | approximate: True  | maxdiff: 4.307366907596588e-09\n"
          ]
        }
      ],
      "source": [
        "# backward pass\n",
        "dlogits = F.softmax(logits, 1)\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "cmp('logits', dlogits, logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA7MVbgLDfKA",
        "outputId": "0e28d849-504e-4076-8dff-58a9e09f2dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64, 27]), torch.Size([64]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits.shape, Yb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7q_4ie0DfKA",
        "outputId": "edcb5211-0f76-49c6-810d-418177f594e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0982, 0.0623, 0.0255, 0.0265, 0.0118, 0.0410, 0.0141, 0.0257, 0.0816,\n",
              "        0.0150, 0.0441, 0.0391, 0.0189, 0.0307, 0.0433, 0.0452, 0.0195, 0.0146,\n",
              "        0.0189, 0.0577, 0.0134, 0.0221, 0.0379, 0.0914, 0.0203, 0.0450, 0.0361],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(logits, 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1PxGMIqDfKA",
        "outputId": "b59a1fb6-ecff-460e-e1ec-e6afe0dfa95e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0982,  0.0623,  0.0255,  0.0265,  0.0118,  0.0410,  0.0141,  0.0257,\n",
              "         0.0816,  0.0150,  0.0441,  0.0391, -0.9811,  0.0307,  0.0433,  0.0452,\n",
              "         0.0195,  0.0146,  0.0189,  0.0577,  0.0134,  0.0221,  0.0379,  0.0914,\n",
              "         0.0203,  0.0450,  0.0361], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dlogits[0] * n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lODa50moDfKB",
        "outputId": "787f477f-c054-4e5b-9ca1-d65933ebbcfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-6.9849e-10, grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dlogits[0].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "Exgi4ikaDfKB",
        "outputId": "1ae3d2d2-23c7-405b-fd5e-d20526317dd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 8))\n",
        "plt.imshow(dlogits.detach(), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMRq37AKDfKB",
        "outputId": "34e80a6e-f28e-4029-b218-c39f160ae566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# now:\n",
        "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuEDT0vwDfKC",
        "outputId": "af6b41dc-4259-4320-e834-103282109e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hprebn          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
          ]
        }
      ],
      "source": [
        "# before we had:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2*bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUBB1qMTDfKC",
        "outputId": "a946ddde-f46f-42bf-d1bf-2d6854c364eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([64, 64]),\n",
              " torch.Size([64]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nQRtPm7DfKC",
        "outputId": "91d4fe82-0691-419e-f1ab-9b75459aac7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12297\n",
            "      0/ 300000: 3.7574\n",
            "  10000/ 300000: 2.1278\n",
            "  20000/ 300000: 2.2110\n",
            "  30000/ 300000: 2.3805\n",
            "  40000/ 300000: 2.3481\n",
            "  50000/ 300000: 2.5489\n",
            "  60000/ 300000: 2.5013\n",
            "  70000/ 300000: 2.4206\n",
            "  80000/ 300000: 2.0369\n",
            "  90000/ 300000: 2.5524\n",
            " 100000/ 300000: 2.3851\n",
            " 110000/ 300000: 2.2343\n",
            " 120000/ 300000: 2.4637\n",
            " 130000/ 300000: 2.2598\n",
            " 140000/ 300000: 2.3715\n",
            " 150000/ 300000: 2.2726\n",
            " 160000/ 300000: 2.4450\n",
            " 170000/ 300000: 2.2943\n",
            " 180000/ 300000: 2.2774\n",
            " 190000/ 300000: 2.4593\n",
            " 200000/ 300000: 2.5401\n",
            " 210000/ 300000: 2.1008\n",
            " 220000/ 300000: 2.3615\n",
            " 230000/ 300000: 2.0875\n",
            " 240000/ 300000: 2.3693\n",
            " 250000/ 300000: 2.4875\n",
            " 260000/ 300000: 2.2724\n",
            " 270000/ 300000: 2.2527\n",
            " 280000/ 300000: 2.2696\n",
            " 290000/ 300000: 2.3104\n"
          ]
        }
      ],
      "source": [
        "# putting all together\n",
        "\n",
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(123432482)\n",
        "C = torch.randn((vocab_size, n_embd), generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3) / ((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn(n_hidden, vocab_size, generator=g) * 0.1 + 1\n",
        "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
        "#BatchNorm\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bnbias, bngain]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "    p.requires_grad = True\n",
        "\n",
        "max_steps = 300000\n",
        "batch_size = 64\n",
        "n = batch_size\n",
        "lossi = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for i in range(max_steps):\n",
        "\n",
        "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "        # forward pass\n",
        "        emb = C[Xb]\n",
        "        embcat = emb.view(emb.shape[0], -1)\n",
        "        # Linear layer\n",
        "        hprebn = embcat @ W1 + b1\n",
        "        # BatchNorm Layer\n",
        "        bnmean = hprebn.mean(0, keepdim=True)\n",
        "        bnvar = hprebn.var(0, keepdim=True)\n",
        "        bnvar_inv = (bnvar + 1e-5) **-0.5\n",
        "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "        hpreact = bngain * bnraw + bnbias\n",
        "        # Non-Linearity\n",
        "        h = torch.tanh(hpreact)\n",
        "        logits = h @ W2 + b2\n",
        "        loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "        #backward pass\n",
        "        for p in parameters:\n",
        "            p.grad = None\n",
        "        #loss.backward() # we do not this anymore\n",
        "\n",
        "        # manual backprop!\n",
        "        dlogits = F.softmax(logits, 1)\n",
        "        dlogits[range(n), Yb] -=1\n",
        "        dlogits /= n\n",
        "        # 2nd layer backprop\n",
        "        dh = dlogits @ W2.T\n",
        "        dW2 = h.T @ dlogits\n",
        "        db2 = dlogits.sum(0)\n",
        "        # tanh\n",
        "        dhpreact = (1.0 - h**2) * dh\n",
        "        # batchnorm backprop\n",
        "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "        # 1st layer\n",
        "        dembcat = dhprebn @ W1.T\n",
        "        dW1 = embcat.T @ dhprebn\n",
        "        db1 = dhprebn.sum(0)\n",
        "        # embedding\n",
        "        demb = dembcat.view(emb.shape)\n",
        "        dC = torch.zeros_like(C)\n",
        "        for k in range(Xb.shape[0]):\n",
        "            for j in range(Xb.shape[1]):\n",
        "                ix = Xb[k,j]\n",
        "                dC[ix] += demb[k,j]\n",
        "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "\n",
        "        #update\n",
        "        lr = 0.1 if i < 250000 else 0.05 if i < 300000 else 0.01 # step learning rate decay\n",
        "        for p, grad in zip(parameters, grads):\n",
        "            #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "            p.data += -lr * grad\n",
        "\n",
        "        # track stats\n",
        "        if i % 10000 == 0: # print every once in a while\n",
        "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "        lossi.append(loss.log10().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jquggN5SDfKD"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzbYAIc5DfKD",
        "outputId": "f82da962-595a-4ffc-9d0f-f2531365f7ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 2.2336275577545166\n",
            "val 2.2382757663726807\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xtest, Ytest),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMBoMaZRDfKD",
        "outputId": "44bc72af-0219-4715-ff25-1d051e4a3d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eria.\n",
            "kayah.\n",
            "seen.\n",
            "ndhayah.\n",
            "rethrshendraeg.\n",
            "adered.\n",
            "eliigh.\n",
            "porea.\n",
            "eden.\n",
            "estanar.\n",
            "kateivelka.\n",
            "cayshabergahirie.\n",
            "tan.\n",
            "jowellionno.\n",
            "adriu.\n",
            "zayven.\n",
            "jamell.\n",
            "ehs.\n",
            "kaysh.\n",
            "sanyan.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # ------------\n",
        "      # forward pass:\n",
        "      # Embedding\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # ------------\n",
        "      # Sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7un_D7dDfKD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
